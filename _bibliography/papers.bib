@article{pokeflex,
  author    = {Obrist, Jan and Zamora, Miguel and Zheng, Hehui and Hinchet, Ronan and Ozdemir, Firat and Zarate, Juan and Katzschmann, Robert K. and Coros, Stelian},
  title     = {PokeFlex: A Real-World Dataset of Deformable Objects for Robotics},
  year      = {2024},
  journal   = {Preprint},
  preview={objects.pdf},
  website = {https://pokeflex-dataset.github.io/},
  arXiv = {https://arxiv.org/abs/2410.07688},
  abstract={Data-driven methods have shown great potential in solving challenging manipulation tasks, however, their application in the domain of deformable objects has been constrained, in part, by the lack of data. To address this, we propose PokeFlex, a dataset featuring real-world paired and annotated multimodal data that includes 3D textured meshes, point clouds, RGB images, and depth maps. Such data can be leveraged for several downstream tasks such as online 3D mesh reconstruction, and it can potentially enable underexplored applications such as the real-world deployment of traditional control methods based on mesh simulations. To deal with the challenges posed by real-world 3D mesh reconstruction, we leverage a professional volumetric capture system that allows complete 360Â° reconstruction. PokeFlex consists of 18 deformable objects with varying stiffness and shapes. Deformations are generated by dropping objects onto a flat surface or by poking the objects with a robot arm. Interaction forces and torques are also reported for the latter case. Using different data modalities, we demonstrated a use case for the PokeFlex dataset in online 3D mesh reconstruction. We refer the reader to our website for demos and examples of our dataset.},
}

@article{pokeflexExtendedAbstract,
  author    = {Obrist, Jan and Zamora, Miguel and Zheng, Hehui and Zarate, Juan and Katzschmann, Robert K. and Coros, Stelian},
  title     = {PokeFlex: Towards a Real-World Dataset of Deformable Objects for Robotic Manipulation},
  year      = {2024},
  journal   = {Extended abstract. ICRA40},
  preview={setup.jpg},
  website = {https://pokeflex-dataset.github.io/},
  arXiv = {https://arxiv.org/abs/2409.17124},
  abstract={Advancing robotic manipulation of deformable objects can enable automation of repetitive tasks across multiple industries, from food processing to textiles and healthcare. Yet robots struggle with the high dimensionality of deformable objects and their complex dynamics. While data-driven methods have shown potential for solving manipulation tasks, their application in the domain of deformable objects has been constrained by the lack of data. To address this, we propose PokeFlex, a pilot dataset featuring real-world 3D mesh data of actively deformed objects, together with the corresponding forces applied by a robotic arm, using a simple poking strategy. Deformations are captured with a professional volumetric capture system that allows for complete 360-degree reconstruction. The PokeFlex dataset consists of five deformable objects with varying stiffness and shapes. Additionally, we leverage the PokeFlex dataset to train a vision model for online 3D mesh reconstruction from a single image and a template mesh. We refer readers to the supplementary material for demos and examples of our dataset.},
}
